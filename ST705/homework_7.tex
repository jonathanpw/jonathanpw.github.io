\documentclass[11pt]{article}
\usepackage{amsmath,amssymb,color,float}
\usepackage{graphicx,psfrag,epsf}
\usepackage{natbib}


\setlength{\oddsidemargin}{.15in} 
\setlength{\textwidth}{6.25in}
\setlength{\topmargin}{-0.25in}
\setlength{\headheight}{-0.15in}
\setlength{\textheight}{8.9in} 

\linespread{1.25}


\title{ST 705 Linear models and variance components \\ 
        Homework problem set 7}


\begin{document}
\maketitle

\begin{enumerate}

\item Monahan exercise 3.9 not necessary to do the ``(More practice)'' item.

\item Monahan exercise 3.24.

\item Consider the simple linear regression model $y_{i} = \beta_{0} + \beta_{1}x_{i} + u_{i}$ for $i \in \{1,\dots,n\}$.  Show that if the $x_{i}$ are equally spaced (i.e., $x_{i} = s + ti$ for some scalars $s$ and $t$), then $y_{i} = \gamma_{0} + \gamma_{1}i + u_{i}$ is a reparameterization.

\item Consider the vector space, $P_{3}(\mathbb{R})$, of polynomials over $\mathbb{R}$ with degree at most 3, and with the inner product $\langle f, g\rangle := \int_{-1}^{1}f(t)g(t) \ dt$.  Beginning with the standard basis, $\{1, x, x^{2}, x^{3}\}$, construct an orthonormal basis for $P_{3}(\mathbb{R})$.

\item Suppose that $v_{1},\dots,v_{p} \in \mathbb{R}^{n}$ are a set of linearly independent vectors, and $w_{1},\dots,w_{p} \in \mathbb{R}^{n}$ are the orthogonal vectors obtained from $v_{1},\dots,v_{p}$ by the Gram-Schmidt process.  Furthermore, denote by $u_{1},\dots,u_{p}$ the normalized vectors corresponding to $w_{1},\dots,w_{p}$, and define the matrix $R \in \mathbb{R}^{p\times p}$ by
\[
R_{ij} :=
\begin{cases}
\|w_{j}\| & \text{if } i=j \\
\langle v_{j}, u_i\rangle & \text{if } i<j \\
0 & \text{if } i>j \\
\end{cases}.
\]
Prove that $V = UR$, where $V$ is the matrix with columns $v_{1},\dots,v_{p}$ and $U$ is the matrix with columns $u_{1},\dots,u_{p}$.

\item In the notation of the previous problem, suppose that $p = n$.  Further, assume that $V = U_{1}R_{1} = U_{2}R_{2}$, where $U_{1}$ and $U_{2}$ are orthogonal matrices and $R_{1}$ and $R_{2}$ are upper triangular.  Prove that the matrix $R_{2}R_{1}^{-1}$ is orthogonal and diagonal.

\end{enumerate}



\end{document}